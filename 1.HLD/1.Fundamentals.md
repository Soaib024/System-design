# Basics 

### 1. An Introduction to distributed system
### 2. Horizontal vs Vertical Scaling
### 3. Monoliths vs Microservices
### 4. Load Balancing
### 5. Sharding
### 6. Single Point of Failure
### 7. Service Discovery and Heart Beat
### 8. Capacity Planning and Estimation
### 9. Content Delivery Network

# API Design

### 1. API Design Goals
### 2. API Design in Practice

# Database Deep Dive

### 1. What are Databases
### 2. Storage and Retrieval
### 3. What are NoSQL Databases
### 4. Types of Databases
### 5. What Database should we choose

# Messaging and Event Handling

### 1. The Message Queue: Problem Statement
### 2. Asynchronous Processing: Benefits
### 3. Publisher Subscriber Models
- If there is no strong consistency guarantee to be made for transactions, an event model is good to use in microservices.

### Advantages:
- Decouples a system's services.
- Easily add subscribers and publishers without informing the other.
- Converts multiple points of failure to a single point of failure.
- Interaction logic can be moved to services/ message broker.
### Disadvantages:
- An extra layer of interaction slows services
- Cannot be used in systems requiring strong consistency of data
- Additional cost to the team for redesigning, learning, and maintaining the message queues.


### 4. Event Driven Architecture


# Consistency in Distributed Systems
### 1. What is Data Consistency
- Consistency in a distributed system refers to how up-to-date a piece of data is.

### 2. Linearizable Consistency
- Highest level of consistency
- All changes which have happened in the database before the read operation will be reflected in the read query. 
- To achieve this we use a single-threaded single server. So every read-and-write request will always be ordered. 
- **Head of line blocking** - If some request is blocking server all other request will starve
- High latency, low availability and SPOF
- High consistency and easy to debug
- Spanner, FaunaDB


### Implementation
- Single Thread
- RAFT

### 3. Eventual Consistency
- At this level of consistency, we can send stale data for a read request.
- Eventually, our systems catch up with all updates and return fresh data.
- we can process read and write requests parallelly using multiple threads and/or multiple servers.
- **Note** Eventual consistency is a very loose guarantee, and is often coupled with stronger guarantees like "read your writes".
- Amazon DynamoDB, Apache Cassandra, Couchbase, MongoDB (with configurable consistency options), Redis, Memcached.


### 4. Causal Consistency
- If a previous operation is related to the current operation, then the previous operation must be executed before the current operation.
- Causal consistency is stronger and slower than eventual consistency because operations for the same key are processed sequentially.
- It is looser and faster than the linearizable and serializable consistency level because it does not wait for all previous operations to complete.
- Multiple operation for the same key will execute on a same server and possibly same thread, server will acquire global lock on a key till operation is completed.
- If we don't have a system to sequentially order the request for same key then there will be a race condition.
- It won't work for aggregate query. example sum
- CockroachDB, YugaByte DB


### 5. Quorum
- We have multiple replicas of data
- When there's a read request, query all of the replicas, then return f(all replica response), here f could be majority voting, latest timestamp, etc
- We can get consistency guarantees based on our requirements.

```
It defines how many readers must acknowledge a read operation = R.
It also defines how many writers must acknowledge a write operation = W. 
We must have a majority to take any action
We can either have an eventually consistent system (R + W <= N) or a strongly consistent system (R + W > N)

```

### 6. Data Consistency Levels Tradeoffs

|             | Linearizable | Eventual | Causal  | Quorum       |
|-------------|--------------|----------|---------|--------------|
| Consistency | Highest      | Lowest   | Mid-way | Configurable |
| Efficiency  | Lowest       | Highest  | Mid-way | Configurable |

- We may have cache at eventual consistency and database at linearizable/serializable

### 7. Transaction Isolation Levels
- Transactions are a collection of queries that perform one unit of work. They are atomic which means either all queries in a transaction are executed or none of it is executed.
- **Begin:** Marks the start of the transaction.
- **Commit:** Marks the end of the transaction, which results in the changes persisting to the database.
- **Rollback:** Marks the end of the transaction and undoes all the changes to the database.
- **Isolation:** If two transactions are running concurrently and queries in one transaction do not affect the other transaction then the two transactions are said to be isolated from each other. 


### 7. Read Uncommitted Data
- Even uncommitted data can be read by concurrent transactions. Although it is very fast, it leads to dirty reads if transactions rolled back. 
- We only need a single entry in the database and it is overwritten whenever there is an update operation

### 8. Read Committed
- One transaction can only read committed data from other transactions.
- For each transaction there will be a local copy
- If we are making an update to a key then the older value of the key stays in the database and the newer value is kept in the local copy till the commit finally goes through. 


### 9. Repeatable Reads
- Same tuple returned between consecutive reads in a same transaction.
- If two transactions concurrently change the same key to different values, we must roll back one transaction.
- This is called Optimistic Concurrency Control since we are optimistic about our changes until they are proven incompatible. 
- We take the values that we care about but we are not changing and keep a version of them. For every key, we will store all the values that it has ever had in different transaction commits


### 10. Serializable Isolation Level
- This is the highest isolation level. At this level, all transactions are executed serially. All of the operations are executed serially or every operation is ensured to not meddle with the operations of other transactions. 
- We use this isolation level when we want to avoid Phantom Reads. 
- We use causal ordering here. If two transactions use queries for the same key then they must be ordered. Transactions that do not have any conflict can run concurrently.

# Caches Deep Dive

### 1. Caching: Basic
- Bad eviction policy could lead to more cache miss than it.
- If cache size is very small then there could be thrashing. 
- Data consistency between cache and DB can be problem.

### 2. Caching: Global vs Local Cache
- Local cache -> Server's local memory
```
Say we have three boxes and each one uses a local cache to store data. If we want to update the profile data of a user, we need to send requests to all the boxes. This is a fan out.

To avoid fanouts we can shard the data and distribute load across the boxes using a load balancing algorithm (like consistent hashing). But what if one of the nodes fails? To avoid this we can replicate the data to multiple nodes. However, this can lead to data inconsistency. So using a local cache reduces data consistency while increasing response time.
```

- Global cache -> Redis with multiple nodes
```
This improves the data consistency but reduces the response time (because we have to make network calls).

There will be a set of nodes and each node will have a set of key-value pairs.

If Data could be sharded then coordinator can forward to the request to correct shard

If node are replica of each other then we can use Quorum
```

### 3. Caching: Write Policies
- A write request means some entry is added, updated or deleted in the cache. But because a cache is a source of truth each of the write requests will impact the entire system

### 4. Write Policies: Write Back
- If the key-value pair that is to be updated is present in the cache then it is updated. However, the key-value pair is not immediately updated in the database.
- So as long as the cache is alive, users will get consistent data. However, if the cache is not alive, the data will be stale.
- Eventual Consistency and we might loss some data in cache crashes

To avoid this problem we use:
```
Timeout-Based Persistence (TTL)
Event-Based Write Back (Batch Write)
Replacement Write Back
```

### 5. Write Policies: Write Through
- Write cache and DB simultaneously, only acknowledge when both write are successful.
- This policy is useful When we need a high level of consistency When we need a high level of persistence However, it is less efficient compared to the write-back policy.

- In some read world distributed system when there is a write request, we evict the key that is being updated, while simultaneously updating the database. - The next time there is a read request, that is when the cache polls the database for the entry, persists the entry and sends the response to the user.
- If we have deleted a entry from a cache due to write request and in between there's a read request for same tuple, the we need to make DB call and returned tuple will depends on execution order of write and read operation.

### 6. Write Policies: Write Around
- When we get a write request, instead of updating the entry in the cache, we update the entry in the database. 
- Now when we get a read request, we will send the stale value from the cache. And we will be getting stale values until the entry is evicted from the cache.
- This policy is useful When we need a high level of efficiency When we need a high level of persistence However, it makes our system eventually consistent.
- Persistence, Eventual Consistency and Efficient

### 7. Replacement Policies: LRU, LFU and Segmented LRU
- LFU might have thrashing problem
- Most cache use LRU in read world
- **Segmented LRU/(LRU + LFU):** Contains two cache *warm* and *cold*, entry start from cold cache, might be promoted to warm based on frequency, for eviction and demotion to cold region LRU is used.
- Memcached has three cache *hot*, *warm* and *cold*, all new entry is added to hot and they will eventually pushed either to warm or cold.

# Networks
